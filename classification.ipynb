{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maoyiyun/opt/anaconda3/envs/DL/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>subreddit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jchannon</td>\n",
       "      <td>This looks great, will check it out.  Surprise...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;This looks great, will chec...</td>\n",
       "      <td>1548355257</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>eev2r1k</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_ajbhjw</td>\n",
       "      <td>t3_ajbhjw</td>\n",
       "      <td>/r/ElectricCarUK/comments/ajbhjw/ive_made_an_a...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>ElectricCarUK</td>\n",
       "      <td>t5_o9449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Super thrilled you’ve done this! 1 small thing...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;Super thrilled you’ve done ...</td>\n",
       "      <td>1548368952</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>eevop91</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_ajbhjw</td>\n",
       "      <td>t3_ajbhjw</td>\n",
       "      <td>/r/ElectricCarUK/comments/ajbhjw/ive_made_an_a...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>ElectricCarUK</td>\n",
       "      <td>t5_o9449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antpk</td>\n",
       "      <td>Love it but unfortunately I'm on Android.</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;Love it but unfortunately I...</td>\n",
       "      <td>1548331143</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>eeu6fez</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_ajbhjw</td>\n",
       "      <td>t3_ajbhjw</td>\n",
       "      <td>/r/ElectricCarUK/comments/ajbhjw/ive_made_an_a...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>ElectricCarUK</td>\n",
       "      <td>t5_o9449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FillingUpTheDatabase</td>\n",
       "      <td>From 10th June 2021 this will be the pricing f...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;From 10th June 2021 this wi...</td>\n",
       "      <td>1622556382</td>\n",
       "      <td>None</td>\n",
       "      <td>1622557075</td>\n",
       "      <td>h070epp</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>t3_npusqp</td>\n",
       "      <td>t3_npusqp</td>\n",
       "      <td>/r/ElectricCarUK/comments/npusqp/bp_pulse_pric...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>ElectricCarUK</td>\n",
       "      <td>t5_o9449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happysleepygoat</td>\n",
       "      <td>I’m confused by this email. \\n\\nMy workplace h...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;I’m confused by this email....</td>\n",
       "      <td>1622559742</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>h077ld1</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_npusqp</td>\n",
       "      <td>t3_npusqp</td>\n",
       "      <td>/r/ElectricCarUK/comments/npusqp/bp_pulse_pric...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>ElectricCarUK</td>\n",
       "      <td>t5_o9449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                               body  \\\n",
       "0              jchannon  This looks great, will check it out.  Surprise...   \n",
       "1             [deleted]  Super thrilled you’ve done this! 1 small thing...   \n",
       "2                 antpk         Love it but unfortunately I'm on Android.    \n",
       "3  FillingUpTheDatabase  From 10th June 2021 this will be the pricing f...   \n",
       "4       happysleepygoat  I’m confused by this email. \\n\\nMy workplace h...   \n",
       "\n",
       "                                           body_html  created_utc  \\\n",
       "0  <div class=\"md\"><p>This looks great, will chec...   1548355257   \n",
       "1  <div class=\"md\"><p>Super thrilled you’ve done ...   1548368952   \n",
       "2  <div class=\"md\"><p>Love it but unfortunately I...   1548331143   \n",
       "3  <div class=\"md\"><p>From 10th June 2021 this wi...   1622556382   \n",
       "4  <div class=\"md\"><p>I’m confused by this email....   1622559742   \n",
       "\n",
       "  distinguished      edited       id is_submitter    link_id  parent_id  \\\n",
       "0          None        None  eev2r1k         None  t3_ajbhjw  t3_ajbhjw   \n",
       "1          None        None  eevop91         None  t3_ajbhjw  t3_ajbhjw   \n",
       "2          None        None  eeu6fez         None  t3_ajbhjw  t3_ajbhjw   \n",
       "3          None  1622557075  h070epp         TRUE  t3_npusqp  t3_npusqp   \n",
       "4          None        None  h077ld1         None  t3_npusqp  t3_npusqp   \n",
       "\n",
       "                                           permalink saved  score stickied  \\\n",
       "0  /r/ElectricCarUK/comments/ajbhjw/ive_made_an_a...  None      2     None   \n",
       "1  /r/ElectricCarUK/comments/ajbhjw/ive_made_an_a...  None      2     None   \n",
       "2  /r/ElectricCarUK/comments/ajbhjw/ive_made_an_a...  None      2     None   \n",
       "3  /r/ElectricCarUK/comments/npusqp/bp_pulse_pric...  None      2     None   \n",
       "4  /r/ElectricCarUK/comments/npusqp/bp_pulse_pric...  None      1     None   \n",
       "\n",
       "  subreddit_name subreddit_id  \n",
       "0  ElectricCarUK     t5_o9449  \n",
       "1  ElectricCarUK     t5_o9449  \n",
       "2  ElectricCarUK     t5_o9449  \n",
       "3  ElectricCarUK     t5_o9449  \n",
       "4  ElectricCarUK     t5_o9449  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UK_df = pd.read_csv('data/ElectricCarUK-comments.csv')\n",
    "UK_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>subreddit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JacksonDWalter</td>\n",
       "      <td>Something similar to this occurred at a loft m...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;Something similar to this o...</td>\n",
       "      <td>1698195708</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>k6bxtk8</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>/r/evcharging/comments/17fryug/mind_your_idle_...</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "      <td>evcharging</td>\n",
       "      <td>t5_vprim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nxtiak</td>\n",
       "      <td>What a fool. I've unplugged people that finish...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;What a fool. I&amp;#39;ve unplu...</td>\n",
       "      <td>1698193918</td>\n",
       "      <td>None</td>\n",
       "      <td>1698194101</td>\n",
       "      <td>k6btdk7</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>/r/evcharging/comments/17fryug/mind_your_idle_...</td>\n",
       "      <td>None</td>\n",
       "      <td>94</td>\n",
       "      <td>None</td>\n",
       "      <td>evcharging</td>\n",
       "      <td>t5_vprim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illcatchyoubeerbaron</td>\n",
       "      <td>My office has some free chargers for employees...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;My office has some free cha...</td>\n",
       "      <td>1698209135</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>k6crcgj</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>/r/evcharging/comments/17fryug/mind_your_idle_...</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>evcharging</td>\n",
       "      <td>t5_vprim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>odinsen251a</td>\n",
       "      <td>New high score!</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;New high score!&lt;/p&gt;\\n&lt;/div&gt;</td>\n",
       "      <td>1698205954</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>k6cll3q</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>/r/evcharging/comments/17fryug/mind_your_idle_...</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>evcharging</td>\n",
       "      <td>t5_vprim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simplystriking</td>\n",
       "      <td>I ain't unplugging shit, they wanna waste othe...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;I ain&amp;#39;t unplugging shit...</td>\n",
       "      <td>1698225184</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>k6dd0lv</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>t3_17fryug</td>\n",
       "      <td>/r/evcharging/comments/17fryug/mind_your_idle_...</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>evcharging</td>\n",
       "      <td>t5_vprim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                               body  \\\n",
       "0        JacksonDWalter  Something similar to this occurred at a loft m...   \n",
       "1                nxtiak  What a fool. I've unplugged people that finish...   \n",
       "2  Illcatchyoubeerbaron  My office has some free chargers for employees...   \n",
       "3           odinsen251a                                    New high score!   \n",
       "4        simplystriking  I ain't unplugging shit, they wanna waste othe...   \n",
       "\n",
       "                                           body_html  created_utc  \\\n",
       "0  <div class=\"md\"><p>Something similar to this o...   1698195708   \n",
       "1  <div class=\"md\"><p>What a fool. I&#39;ve unplu...   1698193918   \n",
       "2  <div class=\"md\"><p>My office has some free cha...   1698209135   \n",
       "3     <div class=\"md\"><p>New high score!</p>\\n</div>   1698205954   \n",
       "4  <div class=\"md\"><p>I ain&#39;t unplugging shit...   1698225184   \n",
       "\n",
       "  distinguished      edited       id is_submitter     link_id   parent_id  \\\n",
       "0          None        None  k6bxtk8         None  t3_17fryug  t3_17fryug   \n",
       "1          None  1698194101  k6btdk7         None  t3_17fryug  t3_17fryug   \n",
       "2          None        None  k6crcgj         None  t3_17fryug  t3_17fryug   \n",
       "3          None        None  k6cll3q         None  t3_17fryug  t3_17fryug   \n",
       "4          None        None  k6dd0lv         None  t3_17fryug  t3_17fryug   \n",
       "\n",
       "                                           permalink saved  score stickied  \\\n",
       "0  /r/evcharging/comments/17fryug/mind_your_idle_...  None     41     None   \n",
       "1  /r/evcharging/comments/17fryug/mind_your_idle_...  None     94     None   \n",
       "2  /r/evcharging/comments/17fryug/mind_your_idle_...  None     20     None   \n",
       "3  /r/evcharging/comments/17fryug/mind_your_idle_...  None      5     None   \n",
       "4  /r/evcharging/comments/17fryug/mind_your_idle_...  None      5     None   \n",
       "\n",
       "  subreddit_name subreddit_id  \n",
       "0     evcharging     t5_vprim  \n",
       "1     evcharging     t5_vprim  \n",
       "2     evcharging     t5_vprim  \n",
       "3     evcharging     t5_vprim  \n",
       "4     evcharging     t5_vprim  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evcharging_df = pd.read_csv('data/evcharging-comments.csv')\n",
    "evcharging_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "RealTesla_df = pd.read_csv('data/RealTesla-comments.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bolt_df = pd.read_csv('data/BoltEV-comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_columns(df):\n",
    "    # Drop unnecessary columns\n",
    "    df = df[['author','body','score']]\n",
    "    # Rename some columns\n",
    "    df.rename(columns={'body': 'text'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_bot_comment(df): \n",
    "    # Get the list of bots comments\n",
    "    bot_list = [\n",
    "        'Decronym',\n",
    "        'stabbot',\n",
    "        'stabbot_crop',\n",
    "        'DeepFryBot',\n",
    "        'gifreversingbot',\n",
    "        'vredditshare',\n",
    "        'VredditDownloader',\n",
    "        'morejpeg_auto',\n",
    "        'gifendore',\n",
    "        'r2tg_bot',\n",
    "        'WololoBot',\n",
    "        'tippr',\n",
    "        'RemindMeBot',\n",
    "        'profanitycounter',\n",
    "        'Eminem_Bot'\n",
    "    ]\n",
    "\n",
    "    # Check number of posts is bot author\n",
    "    print(f\"Number of bot comments: {df[df['author'].isin(bot_list)].shape[0]}\")\n",
    "    df = df[~df['author'].isin(bot_list)]\n",
    "    df = df.drop(columns=['author'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiple_spaces(text):\n",
    "    # Count\n",
    "    num_substitutions = len(re.findall(r'\\s+', text)) - 1 # Minus 1 because we are replacing with 1 space\n",
    "    # Remove\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    return cleaned_text, num_substitutions\n",
    "def remove_df_extra_spaces(df):\n",
    "    df['text'], counts = zip(*df['text'].apply(remove_multiple_spaces))\n",
    "    print(f\"Number of removed extra spaces: {sum(counts)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_abbr(text):    \n",
    "    abbr_mapper = {\n",
    "        # Reddit abbreviations & Slangs\n",
    "        'Alt': 'Alternative Reddit account',\n",
    "        'AMA': 'Ask me anything',\n",
    "        'AMAA': 'Ask me almost anything',\n",
    "        'Benned': 'Banned',\n",
    "        'Brony': 'Male fan of My Little Pony',\n",
    "        'Cakeday': 'Birthday',\n",
    "        'Circlejerk': 'Elitist group',\n",
    "        'DAE': 'Does anyone else',\n",
    "        'Ent': 'Pot smoker',\n",
    "        'ETA': 'Edited to add',\n",
    "        'F7U12': 'FU',\n",
    "        'Fap': 'Masturbate',\n",
    "        '[FIXED]': 'Remix of an original post',\n",
    "        'FTA': 'From the article',\n",
    "        'FTFY': 'Fixed That For You',\n",
    "        'GW': 'Gone wild',\n",
    "        'Hivemind': 'Collective',\n",
    "        'IAMA': 'I Am A',\n",
    "        'IMO': 'In My Opinion',\n",
    "        'IMHO': 'In my honest opinion',\n",
    "        'IIRC': 'If i recall correctly',\n",
    "        'ITT': 'In this thread',\n",
    "        'Karma': 'Reddit score',\n",
    "        'Karmawhore': 'Desperate for reddit points',\n",
    "        'Meta-sub': 'Subreddits talking about Reddit',\n",
    "        'Meta-subreddits': 'Subreddits talking about Reddit',\n",
    "        'MIC': 'More in comments',\n",
    "        'Mod': 'Moderator',\n",
    "        'MRA': 'Mens rights activist',\n",
    "        'Neckbeard': 'Dirty reddit user',\n",
    "        'Ninjaedit': 'sneaky edit',\n",
    "        'Novelty account': 'joke account',\n",
    "        'NSFW': 'Not safe for work',\n",
    "        'NSFL': 'Not safe for life',\n",
    "        'OP': 'Original Poster',\n",
    "        'Orangered': 'Unread messages',\n",
    "        'Power user': 'User with high reddit score',\n",
    "        'Pun thread': 'Chain of punny comments',\n",
    "        'Reddiquette': 'Rules of reddit',\n",
    "        'RES': 'Reddit enhancement suite',\n",
    "        'RTFA': 'Read the fucking article',\n",
    "        'Shadow-ban': 'Silent ban',\n",
    "        'Shitpost': 'Trash post',\n",
    "        'Sockpuppet': 'Alternate reddit account',\n",
    "        'SJW': 'Social Justice Warrior',\n",
    "        'SRD': 'Subreddit drama',\n",
    "        'SRS': 'Shit reddit says',\n",
    "        'Sub': 'Subreddit',\n",
    "        'TIL': 'Today I learned',\n",
    "        'TL;DR': 'Too Long Didnt read',\n",
    "        'TLDR': 'Too Long Didnt read',\n",
    "        'WIP': 'Work in progress',\n",
    "        'X-post': 'Crosspost',\n",
    "        'Xpost': 'Crosspost',\n",
    "        'wh[o]+sh': 'Dont get the joke',\n",
    "        \n",
    "        # Replace model names with their full brand names as well, Electric car domain specific abbreviations & slangs\n",
    "        \n",
    "        \n",
    "        # Other common internet abbr & slangs\n",
    "        'LOL': 'Laugh out loud',\n",
    "        'TTYL': 'Talk to you later',\n",
    "        'ASAP': 'As soon as possible',\n",
    "        'FYI': 'For your information',\n",
    "        'JK': 'Just kidding',\n",
    "        'IDC': 'I dont care',\n",
    "        'FTW': 'For the win',\n",
    "        'LMAO': 'Laughing my ass off',\n",
    "        'LMFAO': 'Laughing my fucking ass off',\n",
    "        'BFF': 'Best friend forever',\n",
    "        'MFW': 'My face when',\n",
    "        'TFW': 'That feeling when',\n",
    "        'G2G': 'Got to go',\n",
    "        'MSG': 'Message',\n",
    "    }\n",
    "    \n",
    "    # Standardize all cases in mapper\n",
    "    abbr_mapper =  {key.lower(): val for key, val in abbr_mapper.items()}\n",
    "\n",
    "    # Regex to match every key\n",
    "    # r'\\b' -> Matches from start to finish\n",
    "    # (?:) -> Capturing group\n",
    "    # '|'.join(mapper) -> Loop and form pattern of all keys\n",
    "    pattern = r'\\b(?:' + r'|'.join(re.escape(abbr) for abbr in [k.lower() for k in abbr_mapper.keys()]) + r')\\b'\n",
    "    # Compile and replace\n",
    "    pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    # Count\n",
    "    num_substitutions = len(re.findall(pattern, text))\n",
    "    replaced_text = pattern.sub(lambda match: abbr_mapper[match.group(0).lower()], text)\n",
    "\n",
    "    return replaced_text, num_substitutions\n",
    "\n",
    "def df_replace_abbr(df):\n",
    "    # Apply to text field of df\n",
    "    df['text'], counts = zip(*df['text'].apply(replace_abbr))\n",
    "    print(f\"Number of replaced abbreviations: {sum(counts)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count words in a sentence\n",
    "def count_words(sentence):\n",
    "    words = sentence.split()\n",
    "    return len(words)\n",
    "\n",
    "def select_comments(df, min, max):\n",
    "    # Add a column with the number of words in each sentence\n",
    "    df['Word Count'] = df['text'].apply(count_words)\n",
    "    # Select rows with sentences containing 4 to 20 words\n",
    "    selected_rows = df[(df['Word Count'] >= min) & (df['Word Count'] <= max)]\n",
    "    selected_rows = selected_rows.drop(columns=['Word Count'])\n",
    "    print(\"Number of selected rows:\", len(selected_rows))\n",
    "    return selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, min, max):\n",
    "    print(\"Number of rows in original dataset: \", len(df))\n",
    "    df = drop_useless_columns(df)\n",
    "    df = drop_bot_comment(df)\n",
    "    df = remove_df_extra_spaces(df)\n",
    "    df = df_replace_abbr(df)\n",
    "    df = select_comments(df, min, max)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original dataset:  73\n",
      "Number of bot comments: 0\n",
      "Number of removed extra spaces: 4561\n",
      "Number of replaced abbreviations: 0\n",
      "Number of selected rows: 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This looks great, will check it out. Surprised...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super thrilled you’ve done this! 1 small thing...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Love it but unfortunately I'm on Android.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From 10th June 2021 this will be the pricing f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m confused by this email. My workplace has “...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to admit, I have 0 idea how much I spen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is what I’ve been waiting for. The sooner...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This one looks like it has 43kw AC but the one...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I’ve answered your questionnaire. Good luck wi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seems poorly planned not having chargers a vis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  score\n",
       "0   This looks great, will check it out. Surprised...      2\n",
       "1   Super thrilled you’ve done this! 1 small thing...      2\n",
       "2          Love it but unfortunately I'm on Android.       2\n",
       "3   From 10th June 2021 this will be the pricing f...      2\n",
       "4   I’m confused by this email. My workplace has “...      1\n",
       "5   I have to admit, I have 0 idea how much I spen...      1\n",
       "6   This is what I’ve been waiting for. The sooner...      2\n",
       "7   This one looks like it has 43kw AC but the one...      2\n",
       "9   I’ve answered your questionnaire. Good luck wi...      2\n",
       "12  Seems poorly planned not having chargers a vis...      2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_UK_df = preprocess(UK_df, 5, 450)\n",
    "processed_UK_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "#text = \"Covid cases are increasing fast!\"\n",
    "#text = preprocess(text)\n",
    "#encoded_input = tokenizer(processed_UK_df['text'].tolist(), max_length=514, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    #print(text)\n",
    "    encoded_input = tokenizer(text, max_length=500, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    label = config.id2label[ranking[0]]\n",
    "    return scores, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7235768  0.2286789  0.04774429]\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "text = \"Covid cases are increasing fast!\"\n",
    "scores, label = prediction(text)\n",
    "print(scores)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list, labels = zip(*processed_UK_df['text'].apply(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_input = tokenizer(processed_UK_df['text'].tolist(), max_length=500, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#print(text)\n",
    "#encoded_input = tokenizer(text, max_length=500, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(df,name):\n",
    "    print(\"start classification\")\n",
    "    scores_list, labels = zip(*df['text'].apply(prediction))\n",
    "    s_list = np.array(scores_list)\n",
    "    df[\"neg_score\"] = s_list[:, 0]\n",
    "    df[\"neu_score\"] = s_list[:, 1]\n",
    "    df[\"pos_score\"] = s_list[:, 2]\n",
    "    df[\"label\"] = labels\n",
    "    df.to_csv(f\"classification/{name}.csv\",index=False, encoding='utf-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This looks great, will check it out. Surprised...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>0.025596</td>\n",
       "      <td>0.966033</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super thrilled you’ve done this! 1 small thing...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055226</td>\n",
       "      <td>0.147884</td>\n",
       "      <td>0.796890</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Love it but unfortunately I'm on Android.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.356486</td>\n",
       "      <td>0.270438</td>\n",
       "      <td>0.373076</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From 10th June 2021 this will be the pricing f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.898498</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m confused by this email. My workplace has “...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201317</td>\n",
       "      <td>0.765437</td>\n",
       "      <td>0.033245</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to admit, I have 0 idea how much I spen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732036</td>\n",
       "      <td>0.231553</td>\n",
       "      <td>0.036411</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is what I’ve been waiting for. The sooner...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.053832</td>\n",
       "      <td>0.940381</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This one looks like it has 43kw AC but the one...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.498156</td>\n",
       "      <td>0.331384</td>\n",
       "      <td>0.170460</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I’ve answered your questionnaire. Good luck wi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.090637</td>\n",
       "      <td>0.903922</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seems poorly planned not having chargers a vis...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776949</td>\n",
       "      <td>0.208614</td>\n",
       "      <td>0.014437</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  score  neg_score  \\\n",
       "0   This looks great, will check it out. Surprised...      2   0.008371   \n",
       "1   Super thrilled you’ve done this! 1 small thing...      2   0.055226   \n",
       "2          Love it but unfortunately I'm on Android.       2   0.356486   \n",
       "3   From 10th June 2021 this will be the pricing f...      2   0.045968   \n",
       "4   I’m confused by this email. My workplace has “...      1   0.201317   \n",
       "5   I have to admit, I have 0 idea how much I spen...      1   0.732036   \n",
       "6   This is what I’ve been waiting for. The sooner...      2   0.005787   \n",
       "7   This one looks like it has 43kw AC but the one...      2   0.498156   \n",
       "9   I’ve answered your questionnaire. Good luck wi...      2   0.005441   \n",
       "12  Seems poorly planned not having chargers a vis...      2   0.776949   \n",
       "\n",
       "    neu_score  pos_score     label  \n",
       "0    0.025596   0.966033  positive  \n",
       "1    0.147884   0.796890  positive  \n",
       "2    0.270438   0.373076  positive  \n",
       "3    0.898498   0.055533   neutral  \n",
       "4    0.765437   0.033245   neutral  \n",
       "5    0.231553   0.036411  negative  \n",
       "6    0.053832   0.940381  positive  \n",
       "7    0.331384   0.170460  negative  \n",
       "9    0.090637   0.903922  positive  \n",
       "12   0.208614   0.014437  negative  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_UK_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_UK_df.to_csv(\"classification/UK_comment.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original dataset:  1339\n",
      "Number of bot comments: 0\n",
      "Number of removed extra spaces: 48243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/823002335.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'body': 'text'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replaced abbreviations: 63\n",
      "Number of selected rows: 1225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Something similar to this occurred at a loft m...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.687681</td>\n",
       "      <td>0.299403</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a fool. I've unplugged people that finish...</td>\n",
       "      <td>94</td>\n",
       "      <td>0.666745</td>\n",
       "      <td>0.299159</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My office has some free chargers for employees...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.374554</td>\n",
       "      <td>0.534225</td>\n",
       "      <td>0.091221</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I ain't unplugging shit, they wanna waste othe...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.835935</td>\n",
       "      <td>0.153498</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I 100% support this fee and wish it were even ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>0.302278</td>\n",
       "      <td>0.556393</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Laugh out loud! They got charged what they des...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.623661</td>\n",
       "      <td>0.293311</td>\n",
       "      <td>0.083028</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>My apartment charges $10 an hour to idle… this...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.915550</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If I was in a particularly snarktastic mood, I...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.277994</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Airport by me has charging stations with six h...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.449910</td>\n",
       "      <td>0.483379</td>\n",
       "      <td>0.066711</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pfft, looks like my trucks weekly gas bill. La...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.460984</td>\n",
       "      <td>0.348875</td>\n",
       "      <td>0.190141</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I'm sure this person will raise a colossal shi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.900460</td>\n",
       "      <td>0.086521</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I wish they had this at my complex. There are ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068525</td>\n",
       "      <td>0.329112</td>\n",
       "      <td>0.602363</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wow do the guy a favor and unplug it As soon a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.738168</td>\n",
       "      <td>0.240316</td>\n",
       "      <td>0.021516</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Real time Reddit score. Owner is going to shit...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.365583</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Assuming it’s an SAE plug with an adapter why ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.182387</td>\n",
       "      <td>0.794848</td>\n",
       "      <td>0.022766</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  score  neg_score  \\\n",
       "0   Something similar to this occurred at a loft m...     41   0.687681   \n",
       "1   What a fool. I've unplugged people that finish...     94   0.666745   \n",
       "2   My office has some free chargers for employees...     20   0.374554   \n",
       "4   I ain't unplugging shit, they wanna waste othe...      5   0.835935   \n",
       "5   I 100% support this fee and wish it were even ...      3   0.141329   \n",
       "6   Laugh out loud! They got charged what they des...      2   0.623661   \n",
       "7   My apartment charges $10 an hour to idle… this...      2   0.915550   \n",
       "8   If I was in a particularly snarktastic mood, I...      2   0.706766   \n",
       "9   Airport by me has charging stations with six h...      2   0.449910   \n",
       "10  Pfft, looks like my trucks weekly gas bill. La...      2   0.460984   \n",
       "11  I'm sure this person will raise a colossal shi...      2   0.900460   \n",
       "12  I wish they had this at my complex. There are ...      2   0.068525   \n",
       "13  wow do the guy a favor and unplug it As soon a...      2   0.738168   \n",
       "14  Real time Reddit score. Owner is going to shit...      2   0.597139   \n",
       "16  Assuming it’s an SAE plug with an adapter why ...      2   0.182387   \n",
       "\n",
       "    neu_score  pos_score     label  \n",
       "0    0.299403   0.012917  negative  \n",
       "1    0.299159   0.034096  negative  \n",
       "2    0.534225   0.091221   neutral  \n",
       "4    0.153498   0.010567  negative  \n",
       "5    0.302278   0.556393  positive  \n",
       "6    0.293311   0.083028  negative  \n",
       "7    0.076569   0.007881  negative  \n",
       "8    0.277994   0.015240  negative  \n",
       "9    0.483379   0.066711   neutral  \n",
       "10   0.348875   0.190141  negative  \n",
       "11   0.086521   0.013019  negative  \n",
       "12   0.329112   0.602363  positive  \n",
       "13   0.240316   0.021516  negative  \n",
       "14   0.365583   0.037278  negative  \n",
       "16   0.794848   0.022766   neutral  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_evcharging_df = preprocess(evcharging_df,5,500)\n",
    "predict_evcharging = classification(processed_evcharging_df, \"evcharging\")\n",
    "predict_evcharging.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original dataset:  10786\n",
      "Number of bot comments: 0\n",
      "Number of removed extra spaces: 216375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/823002335.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'body': 'text'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replaced abbreviations: 673\n",
      "Number of selected rows: 9320\n",
      "start classification\n"
     ]
    }
   ],
   "source": [
    "processed_RealTesla_df = preprocess(RealTesla_df,5,500)\n",
    "predict_RealTesla = classification(processed_RealTesla_df, \"RealTesla\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each unique value:\n",
      "negative    58.744635\n",
      "neutral     31.030043\n",
      "positive    10.225322\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Absolute count of each unique value:\n",
      "negative    5475\n",
      "neutral     2892\n",
      "positive     953\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get value counts for the 'label' column\n",
    "value_counts = predict_RealTesla['label'].value_counts()\n",
    "\n",
    "# Calculate the total number of values in the column\n",
    "total_count = len(predict_RealTesla)\n",
    "\n",
    "# Calculate the percentage and count for each unique value\n",
    "percentage_counts = (value_counts / total_count) * 100\n",
    "absolute_counts = value_counts\n",
    "\n",
    "# Display the results\n",
    "print(\"Percentage of each unique value:\")\n",
    "print(percentage_counts)\n",
    "print(\"\\nAbsolute count of each unique value:\")\n",
    "print(absolute_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1289, 6)\n",
      "Percentage of each unique value:\n",
      "negative    43.444531\n",
      "neutral     32.660978\n",
      "positive    23.894492\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Absolute count of each unique value:\n",
      "negative    560\n",
      "neutral     421\n",
      "positive    308\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "popular_comment_Tesla = predict_RealTesla[((predict_RealTesla['score'] >= 17)&(predict_RealTesla['label'] == \"negative\"))\\\n",
    "                                           |((predict_RealTesla['score'] >= 9)&(predict_RealTesla['label'] == \"neutral\"))\\\n",
    "                                            |((predict_RealTesla['score'] >= 3)&(predict_RealTesla['label'] == \"positive\"))]\n",
    "print(popular_comment_Tesla.shape)\n",
    "# Get value counts for the 'label' column\n",
    "value_counts = popular_comment_Tesla['label'].value_counts()\n",
    "\n",
    "# Calculate the total number of values in the column\n",
    "total_count = len(popular_comment_Tesla)\n",
    "\n",
    "# Calculate the percentage and count for each unique value\n",
    "percentage_counts = (value_counts / total_count) * 100\n",
    "absolute_counts = value_counts\n",
    "\n",
    "# Display the results\n",
    "print(\"Percentage of each unique value:\")\n",
    "print(percentage_counts)\n",
    "print(\"\\nAbsolute count of each unique value:\")\n",
    "print(absolute_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/3449500806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/3449500806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/3449500806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/3449500806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/3449500806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/3449500806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n"
     ]
    }
   ],
   "source": [
    "popular_comment_Tesla[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
    "popular_comment_Tesla.to_csv(\"classification/popular_comment_Telsa.csv\",index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original dataset:  4439\n",
      "Number of bot comments: 0\n",
      "Number of removed extra spaces: 111377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/823002335.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'body': 'text'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replaced abbreviations: 237\n",
      "Number of selected rows: 3879\n",
      "start classification\n"
     ]
    }
   ],
   "source": [
    "processed_Bolt_df = preprocess(Bolt_df,5,500)\n",
    "predict_Bolt = classification(processed_Bolt_df, \"BoltEV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each unique value:\n",
      "neutral     39.572055\n",
      "negative    37.535447\n",
      "positive    22.892498\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Absolute count of each unique value:\n",
      "neutral     1535\n",
      "negative    1456\n",
      "positive     888\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get value counts for the 'label' column\n",
    "value_counts = predict_Bolt['label'].value_counts()\n",
    "\n",
    "# Calculate the total number of values in the column\n",
    "total_count = len(predict_Bolt)\n",
    "\n",
    "# Calculate the percentage and count for each unique value\n",
    "percentage_counts = (value_counts / total_count) * 100\n",
    "absolute_counts = value_counts\n",
    "\n",
    "# Display the results\n",
    "print(\"Percentage of each unique value:\")\n",
    "print(percentage_counts)\n",
    "print(\"\\nAbsolute count of each unique value:\")\n",
    "print(absolute_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1196, 6)\n",
      "Percentage of each unique value:\n",
      "neutral     35.284281\n",
      "negative    33.612040\n",
      "positive    31.103679\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Absolute count of each unique value:\n",
      "neutral     422\n",
      "negative    402\n",
      "positive    372\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "popular_comment_Bolt = predict_Bolt[((predict_Bolt['score'] >= 4)&(predict_Bolt['label'] == \"negative\"))\\\n",
    "                                           |((predict_Bolt['score'] >= 4)&(predict_Bolt['label'] == \"neutral\"))\\\n",
    "                                            |((predict_Bolt['score'] >= 3)&(predict_Bolt['label'] == \"positive\"))]\n",
    "print(popular_comment_Bolt.shape)\n",
    "# Get value counts for the 'label' column\n",
    "value_counts = popular_comment_Bolt['label'].value_counts()\n",
    "\n",
    "# Calculate the total number of values in the column\n",
    "total_count = len(popular_comment_Bolt)\n",
    "\n",
    "# Calculate the percentage and count for each unique value\n",
    "percentage_counts = (value_counts / total_count) * 100\n",
    "absolute_counts = value_counts\n",
    "\n",
    "# Display the results\n",
    "print(\"Percentage of each unique value:\")\n",
    "print(percentage_counts)\n",
    "print(\"\\nAbsolute count of each unique value:\")\n",
    "print(absolute_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/1452255117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/1452255117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/1452255117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/1452255117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/1452255117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_36576/1452255117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n"
     ]
    }
   ],
   "source": [
    "popular_comment_Bolt[[\"annotator 1\",\"irony 1\",\"remove 1\",\"annotator 2\",\"irony 2\",\"remove 2\"]] = \"\"\n",
    "popular_comment_Bolt.to_csv(\"classification/popular_comment_Bolt.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets to be labelled\n",
    "2 datasets(subtopics): comments for BoltEV and comments for RealTesla. Existing columns: text, score(number of up-votes minus number of down-votes), softmax scores for all three lables, predicted label.\n",
    "\n",
    "### Annotation instruction\n",
    "2 annotators are needed, each of them need to do the following:\n",
    "1. classify the comment as positive(1), neutral(0) or negative(-1) under the column annotater 1(2)\n",
    "2. classify the comment as ironic(1) or unironic(0) under the column irony 1(2)\n",
    "3. if you feel the comment lacks context to the extent that it is difficult to label, put 1 under the column remove 1(2)\n",
    "4. if you feel the comment is not relevant to the subtopic, put 2 under the column remove 1(2)\n",
    "\n",
    "Caveat: \n",
    "* Even you put 1 or 2 under column remove, still fill in the values for anotator and irony columns to the best of your knowledge. \n",
    "* Predicion results from the pre-trained model are available in the csv file. Try not to refer to them too much when doing the labelling. We use the annotators inputs as ground truths.\n",
    "* We hope to have 1000 entries for each dataset. Currently each dataset has around 1.2k entries. That means we can accept around 200 entries to be removed for each dataset.  \n",
    "\n",
    "### Model used for classification\n",
    "A RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark.https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest The checkpoint is found on HuggingFace. No guarantee it will work well on our own dataset but it is the most relevant I can find. No training/finetuning is performed because we do not have labelled data at this time and very likely will not have the time to label extra data besides the 2 test datasets in the future.\n",
    "\n",
    "### Innovation\n",
    "Considering ensemble classification or sarcasm detection. For both the most feasible approach will still be using checkpoints on hugging face. The irony columns are labelled so we can experiment on sarcasm detection, if the results are too bad, may just switch to ensemble classification or other methods that do not require extra labelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotateddf = pd.read_csv('popular_comment_Bolt_annotate_Merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bolt_predicted = pd.read_csv('classification/popular_comment_Bolt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid count:  1068\n"
     ]
    }
   ],
   "source": [
    "annotateddf['annotator_combined'] = np.where(annotateddf['annotator 1'] == annotateddf['annotator 2'], annotateddf['annotator 1'], np.nan)\n",
    "valid_count = annotateddf['annotator_combined'].count()\n",
    "print(\"valid count: \", valid_count)\n",
    "annotateddf.dropna(subset=['annotator_combined'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotateddf['annotator_combined'] = annotateddf['annotator_combined'].astype(str)\n",
    "sentiment_mapping = {'-1.0': 'negative', '0.0': 'neutral', '1.0': 'positive'}\n",
    "\n",
    "annotateddf['annotator_combined'] = annotateddf['annotator_combined'].replace(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove 1: 150\n",
      "remove 2: 150\n"
     ]
    }
   ],
   "source": [
    "remove_count_1 = annotateddf['remove 1'].count()\n",
    "print(\"remove 1:\", remove_count_1)\n",
    "remove_count_2 = annotateddf['remove 2'].count()\n",
    "print(\"remove 2:\", remove_count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common remove:  34\n"
     ]
    }
   ],
   "source": [
    "count_non_na = annotateddf[['remove 1', 'remove 2']].notna().all(axis=1).sum()\n",
    "print(\"common remove: \", count_non_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "annotateddf = annotateddf[annotateddf['remove 1'].isna() | annotateddf['remove 2'].isna()]\n",
    "print(len(annotateddf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df = annotateddf[[\"text\",\"annotator_combined\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator 1</th>\n",
       "      <th>irony 1</th>\n",
       "      <th>remove 1</th>\n",
       "      <th>annotator 2</th>\n",
       "      <th>irony 2</th>\n",
       "      <th>remove 2</th>\n",
       "      <th>annotator_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Ultium based Bolt with NACS and faster char...</td>\n",
       "      <td>219</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.088701</td>\n",
       "      <td>0.906359</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had to have something smaller than the Eq...</td>\n",
       "      <td>141</td>\n",
       "      <td>0.378837</td>\n",
       "      <td>0.540830</td>\n",
       "      <td>0.080333</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes! I just came back to post this very same t...</td>\n",
       "      <td>55</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.984271</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes!!! So excited! Was thinking I was going to...</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017278</td>\n",
       "      <td>0.055458</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interesting that they dropped the EV/EUV namep...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>0.881413</td>\n",
       "      <td>0.086321</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  neg_score  \\\n",
       "0  An Ultium based Bolt with NACS and faster char...    219   0.004940   \n",
       "1  They had to have something smaller than the Eq...    141   0.378837   \n",
       "2  Yes! I just came back to post this very same t...     55   0.003039   \n",
       "3  Yes!!! So excited! Was thinking I was going to...     52   0.017278   \n",
       "4  Interesting that they dropped the EV/EUV namep...     21   0.032266   \n",
       "\n",
       "   neu_score  pos_score     label  annotator 1  irony 1  remove 1  \\\n",
       "0   0.088701   0.906359  positive          NaN      NaN       NaN   \n",
       "1   0.540830   0.080333   neutral          NaN      NaN       NaN   \n",
       "2   0.012690   0.984271  positive          NaN      NaN       NaN   \n",
       "3   0.055458   0.927264  positive          NaN      NaN       NaN   \n",
       "4   0.881413   0.086321   neutral          NaN      NaN       NaN   \n",
       "\n",
       "   annotator 2  irony 2  remove 2 annotator_combined  \n",
       "0          NaN      NaN       NaN            neutral  \n",
       "1          NaN      NaN       NaN           negative  \n",
       "2          NaN      NaN       NaN           positive  \n",
       "3          NaN      NaN       NaN           positive  \n",
       "4          NaN      NaN       NaN            neutral  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(Bolt_predicted, annotation_df, on='text', how='inner')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8191489361702128\n",
      "Precision: 0.8217577552345009\n",
      "Recall: 0.8191489361702128\n",
      "F1 Score: 0.8198113471835082\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(merged_df['annotator_combined'], merged_df['label'])\n",
    "precision = precision_score(merged_df['annotator_combined'], merged_df['label'], average='weighted')\n",
    "recall = recall_score(merged_df['annotator_combined'], merged_df['label'], average='weighted')\n",
    "f1 = f1_score(merged_df['annotator_combined'], merged_df['label'], average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8191489361702128\n",
      "Precision: 0.8191489361702128\n",
      "Recall: 0.8191489361702128\n",
      "F1 Score: 0.8191489361702128\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(merged_df['annotator_combined'], merged_df['label'])\n",
    "precision = precision_score(merged_df['annotator_combined'], merged_df['label'], average='micro')\n",
    "recall = recall_score(merged_df['annotator_combined'], merged_df['label'], average='micro')\n",
    "f1 = f1_score(merged_df['annotator_combined'], merged_df['label'], average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 22:59:13.767067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "config.json: 100%|██████████| 688/688 [00:00<00:00, 45.3kB/s]\n",
      "model.safetensors: 100%|██████████| 1.43G/1.43G [03:11<00:00, 7.44MB/s]\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "tokenizer_config.json: 100%|██████████| 25.0/25.0 [00:00<00:00, 3.77kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.19MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 906kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:01<00:00, 1.33MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('zero-shot-classification', model='roberta-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = merged_df['text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnli_predictin(text):\n",
    "    candidate_labels = ['positive', 'neutral', 'negative']\n",
    "    result = classifier(text, candidate_labels)\n",
    "    scores_list = result[\"scores\"]\n",
    "    labels_list = result[\"labels\"]\n",
    "    chosen_labels = labels_list[0]\n",
    "    return scores_list, labels_list, chosen_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = ['positive', 'neutral', 'negative']\n",
    "result = classifier(text_list, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'today is a bad day',\n",
       "  'labels': ['negative', 'neutral', 'positive'],\n",
       "  'scores': [0.9906196594238281, 0.007247406058013439, 0.0021329601295292377]}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = [d['scores'] for d in result if 'scores' in d]\n",
    "labels_list = [d['labels'] for d in result if 'labels' in d]\n",
    "chosen_labels = list(zip(*labels_list))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list, labels_list, labels = zip(*merged_df['text'].apply(mnli_predictin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"mnli_label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6537717601547389\n",
      "Precision: 0.6937598452290512\n",
      "Recall: 0.6537717601547389\n",
      "F1 Score: 0.6152323371340676\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(merged_df['annotator_combined'], merged_df['mnli_label'])\n",
    "precision = precision_score(merged_df['annotator_combined'], merged_df['mnli_label'], average='weighted')\n",
    "recall = recall_score(merged_df['annotator_combined'], merged_df['mnli_label'], average='weighted')\n",
    "f1 = f1_score(merged_df['annotator_combined'], merged_df['mnli_label'], average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/n573jzn975s_mpdy3pm9tt1h0000gn/T/ipykernel_21964/3355802776.py:1: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vaders = pd.read_csv('VadersTextBlobCombinedData.csv')\n"
     ]
    }
   ],
   "source": [
    "vaders = pd.read_csv('VadersTextBlobCombinedData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = vaders[[\"text\",\"vader_sentiment\"]]\n",
    "combined_df = pd.merge(vaders, merged_df, on='text', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_counts = combined_df[[\"label\",\"mnli_label\",\"vader_sentiment\"]].apply(pd.Series.value_counts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_predictions = vote_counts.idxmax(axis=1)\n",
    "combined_df['consensus_prediction'] = consensus_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### majority voting for reberta, mnli,and vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7350096711798839\n",
      "Precision: 0.7565219647149439\n",
      "Recall: 0.7350096711798839\n",
      "F1 Score: 0.7197461219568052\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(combined_df['annotator_combined'], combined_df['consensus_prediction'])\n",
    "precision = precision_score(combined_df['annotator_combined'], combined_df['consensus_prediction'], average='weighted')\n",
    "recall = recall_score(combined_df['annotator_combined'], combined_df['consensus_prediction'], average='weighted')\n",
    "f1 = f1_score(combined_df['annotator_combined'], combined_df['consensus_prediction'], average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_student_sentiment_classifier (\"I love this movie and i would watch it again and again!\")\n",
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distilled_prediction(text):\n",
    "    #print(text)\n",
    "    result = distilled_student_sentiment_classifier(text,**tokenizer_kwargs)\n",
    "    label = [item['label'] for item in result[0]][0]\n",
    "    scores = [item['score'] for item in result[0]]\n",
    "    return scores, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_scores, distilled_labels = zip(*combined_df['text'].apply(distilled_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"distilled_label\"] = distilled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5135396518375241\n",
      "Precision: 0.5053416348267816\n",
      "Recall: 0.5135396518375241\n",
      "F1 Score: 0.4538706506308806\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(combined_df['annotator_combined'], combined_df['distilled_label'])\n",
    "precision = precision_score(combined_df['annotator_combined'], combined_df['distilled_label'], average='weighted')\n",
    "recall = recall_score(combined_df['annotator_combined'], combined_df['distilled_label'], average='weighted')\n",
    "f1 = f1_score(combined_df['annotator_combined'], combined_df['distilled_label'], average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_counts = combined_df[[\"mnli_label\",\"vader_sentiment\",\"distilled_label\"]].apply(pd.Series.value_counts, axis=1)\n",
    "new_consensus_predictions = vote_counts.idxmax(axis=1)\n",
    "combined_df['new_consensus_predictions'] = new_consensus_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6005802707930368\n",
      "Precision: 0.6005802707930368\n",
      "Recall: 0.6005802707930368\n",
      "F1 Score: 0.6005802707930368\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(combined_df['annotator_combined'], combined_df['new_consensus_predictions'])\n",
    "precision = precision_score(combined_df['annotator_combined'], combined_df['new_consensus_predictions'], average='micro')\n",
    "recall = recall_score(combined_df['annotator_combined'], combined_df['new_consensus_predictions'], average='micro')\n",
    "f1 = f1_score(combined_df['annotator_combined'], combined_df['new_consensus_predictions'], average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_counts = combined_df[[\"label\",\"mnli_label\",\"vader_sentiment\",\"distilled_label\"]].apply(pd.Series.value_counts, axis=1)\n",
    "consensus_predictions4 = vote_counts.idxmax(axis=1)\n",
    "combined_df['consensus_predictions4'] = consensus_predictions4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6876208897485493\n",
      "Precision: 0.6876208897485493\n",
      "Recall: 0.6876208897485493\n",
      "F1 Score: 0.6876208897485493\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(combined_df['annotator_combined'], combined_df['consensus_predictions4'])\n",
    "precision = precision_score(combined_df['annotator_combined'], combined_df['consensus_predictions4'], average='micro')\n",
    "recall = recall_score(combined_df['annotator_combined'], combined_df['consensus_predictions4'], average='micro')\n",
    "f1 = f1_score(combined_df['annotator_combined'], combined_df['consensus_predictions4'], average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"majorityVoting.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
